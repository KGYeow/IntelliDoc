{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ede8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd3abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "  text = text.lower()  # Convert to lowercase\n",
    "  text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and non-alphanumeric characters\n",
    "  text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "  text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "  return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfbf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "def read_document(file_path, filename):\n",
    "    # Text extraction based on file extension\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        with open(file_path, 'rb') as pdf_file:\n",
    "            # Use PyPDF2 for PDF text extraction\n",
    "            pdf_reader = PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        # Use python-docx for Word document text extraction\n",
    "        doc = Document(file_path)\n",
    "        text = \"\"\n",
    "        for paragraph in doc.paragraphs:\n",
    "            text += paragraph.text\n",
    "\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        # Read text directly for TXT files\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            \n",
    "    else:\n",
    "        # Skip unsupported file formats\n",
    "        return None\n",
    "    \n",
    "    # Preprocessing steps (clean text, lowercase, etc.)\n",
    "    text = clean_text(text) # Implement your cleaning function here\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f92b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:\\Documents\\USM\\USM_NotesExercises\\Year 4 Sem 1\\CAT405\\Logistic Regression Model\\Dataset\" # Replace with your data directory path\n",
    "documents = []\n",
    "labels = []\n",
    "for class_dir in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_dir)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, filename)\n",
    "            text = read_document(file_path, filename)\n",
    "            \n",
    "            # Skip unsupported file formats\n",
    "            if text == None:\n",
    "                continue\n",
    "\n",
    "            documents.append(text)\n",
    "            labels.append([filename, class_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97be244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc Name</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic Calendar 2020_2021.pdf</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Academic Calendar 2021_2022.pdf</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academic Calendar 2022_2023.pdf</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academic Calendar 2023_2024.pdf</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Academic.pdf</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Personnel_95.txt</td>\n",
       "      <td>Personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Personnel_96.txt</td>\n",
       "      <td>Personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Personnel_97.txt</td>\n",
       "      <td>Personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Personnel_98.txt</td>\n",
       "      <td>Personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Personnel_99.txt</td>\n",
       "      <td>Personnel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Doc Name      Class\n",
       "0    Academic Calendar 2020_2021.pdf   Academic\n",
       "1    Academic Calendar 2021_2022.pdf   Academic\n",
       "2    Academic Calendar 2022_2023.pdf   Academic\n",
       "3    Academic Calendar 2023_2024.pdf   Academic\n",
       "4                       Academic.pdf   Academic\n",
       "..                               ...        ...\n",
       "609                 Personnel_95.txt  Personnel\n",
       "610                 Personnel_96.txt  Personnel\n",
       "611                 Personnel_97.txt  Personnel\n",
       "612                 Personnel_98.txt  Personnel\n",
       "613                 Personnel_99.txt  Personnel\n",
       "\n",
       "[614 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(labels, columns=['Doc Name', 'Class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7353e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "y = df['Class']\n",
    "\n",
    "joblib.dump(vectorizer, 'TFIDFvectorizer.pkl')\n",
    "vectorizer_dict = {\n",
    "  \"Vocabulary\": {word: int(value) for word, value in vectorizer.vocabulary_.items()},\n",
    "  \"IDF\": vectorizer.idf_.tolist(),\n",
    "}\n",
    "with open(\"TFIDFvectorizer.json\", \"w\") as f:\n",
    "  json.dump(vectorizer_dict, f)\n",
    "# with open(\"TFIDFvectorizer.json\", \"wb\") as f:\n",
    "#   joblib.dump(vectorizer, f)\n",
    "# print(vectorizer)\n",
    "# Save the vectorizer to a file\n",
    "# import msgpack\n",
    "# vocabulary = {word: int(value) for word, value in vectorizer.vocabulary_.items()} # Convert numpy int32 values to regular integers\n",
    "# with open(\"TFIDFvectorizer.msgpack\", \"wb\") as f:\n",
    "#     msgpack.pack((vocabulary), f)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=800)\n",
    "trainedModel = model.fit(X_train, y_train)\n",
    "\n",
    "# dense_features = X_train.toarray()\n",
    "# model = model.fit(dense_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b1b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.3170731707317073 \n",
      "\n",
      "Confusion Matrix:\n",
      "[[37  0  1  0  0]\n",
      " [14  0  0  0  0]\n",
      " [22  0  2  0  0]\n",
      " [17  0  0  0  0]\n",
      " [29  0  1  0  0]] \n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Academic       0.31      0.97      0.47        38\n",
      "Administrative       0.00      0.00      0.00        14\n",
      " Co-curricular       0.50      0.08      0.14        24\n",
      "     Financial       0.00      0.00      0.00        17\n",
      "     Personnel       0.00      0.00      0.00        30\n",
      "\n",
      "      accuracy                           0.32       123\n",
      "     macro avg       0.16      0.21      0.12       123\n",
      "  weighted avg       0.19      0.32      0.17       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kokgu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kokgu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kokgu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = trainedModel.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f1e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Predicted Class   : Academic\n",
      "Predicted Classes : ['Academic', 'Administrative', 'Co-curricular'] \n",
      "\n",
      "~~~~~~~~~~ Predicted Probability ~~~~~~~~~~\n",
      "Predicted probability:\n",
      "Business\t: 0.6746917259678679\n",
      "Entertainment\t: 0.1317899152055091\n",
      "Food\t\t: 0.12092210251531037\n",
      "Graphics\t: 0.03794974219735643\n",
      "Historical\t: 0.03464651411395627\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26016\\532189684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Graphics\\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Historical\\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Medical\\t\\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Politics\\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Space\\t\\t:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "# Use the model for prediction\n",
    "input_file_directory = r\"D:\\Documents\\USM\\USM_NotesExercises\\Year 4 Sem 1\\CAT405\\dataset\\Food\\food_1.txt\"\n",
    "input_file_name = input_file_directory.split(\"\\\\\")[-1]\n",
    "new_document = read_document(input_file_directory, input_file_name)\n",
    "new_features = vectorizer.transform([new_document])\n",
    "prediction = trainedModel.predict(new_features)\n",
    "prediction_proba = trainedModel.predict_proba(new_features)\n",
    "\n",
    "# Function to get predicted classes exceeding the threshold\n",
    "def get_predicted_classes(probabilities):\n",
    "    threshold = 0.1\n",
    "    class_labels = df['Class'].unique()\n",
    "    top_classes = [class_labels[i] for i, p in enumerate(probabilities[0]) if p > threshold]\n",
    "    return top_classes\n",
    "\n",
    "predicted_classes = get_predicted_classes(prediction_proba)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"Predicted Class   :\", prediction[0])\n",
    "print(\"Predicted Classes :\", predicted_classes, \"\\n\")\n",
    "print(\"~~~~~~~~~~ Predicted Probability ~~~~~~~~~~\")\n",
    "print(\"Predicted probability:\")\n",
    "print(\"Academic\\t:\", prediction_proba[0][0])\n",
    "print(\"Administrative\\t:\", prediction_proba[0][1])\n",
    "print(\"Co-curricular\\t\\t:\", prediction_proba[0][2])\n",
    "print(\"Financial\\t:\", prediction_proba[0][3])\n",
    "print(\"Personnel\\t:\", prediction_proba[0][4])\n",
    "# print(\"Medical\\t\\t:\", prediction_proba[0][5])\n",
    "# print(\"Politics\\t:\", prediction_proba[0][6])\n",
    "# print(\"Space\\t\\t:\", prediction_proba[0][7])\n",
    "# print(\"Sport\\t\\t:\", prediction_proba[0][8])\n",
    "# print(\"Technologie\\t:\", prediction_proba[0][9])\n",
    "print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9143d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(model, 'DocClassificationLrModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline conversion complete!\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn\n",
    "\n",
    "# Convert the model to ONNX\n",
    "# initial_type = [('features', onnx.TensorProto.FLOAT)] # Use onnx.TensorProto.FLOAT32\n",
    "initial_type = [('features', FloatTensorType([None, None]))]\n",
    "onx = convert_sklearn(trainedModel, initial_types=initial_type)\n",
    "\n",
    "# Save the converted model\n",
    "with open(\"DocClassificationLrModel.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "print(\"Pipeline conversion complete!\")\n",
    "\n",
    "# pklmodel = joblib.load(r\"D:\\Documents\\USM\\USM_NotesExercises\\Year 4 Sem 1\\CAT405\\Logistic Regression Model\\DocClassificationLrModel.pkl\")\n",
    "# onnx.save_model(pklmodel, \"DocClassificationLrModel.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
